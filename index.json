[{"authors":null,"categories":null,"content":"I am a PhD student at Inria Lille (team Scool, formerly SequeL) \u0026amp; CRIStAL (CNRS) under the supervision of Philippe Preux and Odalric-Ambrym Maillard, funded by the B4H project.\nMy research focuses on reinforcement learning and stochastic bandits in non-stationary and risky environments, with applications to patients follow-up and healthcare planning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1639491175,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a PhD student at Inria Lille (team Scool, formerly SequeL) \u0026amp; CRIStAL (CNRS) under the supervision of Philippe Preux and Odalric-Ambrym Maillard, funded by the B4H project.\nMy research focuses on reinforcement learning and stochastic bandits in non-stationary and risky environments, with applications to patients follow-up and healthcare planning.","tags":null,"title":"Patrick Saux","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  Overview    Overview Optimal control, stochastic and structured bandits, model-based MDP, planning, deep reinforcement learning.\nTeaching assistant for practical sessions.\n Deep Reinforcement Learning Policy gradient, Reinforce, PPO, Unity.   Model-based Model-based MDP: value iteration when the transition probabilities and rewards are known, UCRL algorithms when they are estimated from observations.   Planning Planning in bandits: pure exploration, best arm identification. Planning in MDP: Monte Carlo Tree Search.   ","date":1643155200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1647337605,"objectID":"650ba5cb095925756b8b5073501bb533","permalink":"https://sauxpa.github.io/teaching/rl_x_2022/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/teaching/rl_x_2022/","section":"teaching","summary":"Introduction to reinforcement learning, control and bandits.","tags":null,"title":"Reinforcement Learning (MAP/INF641, M2 Artificial Intelligence and Advanced Visual Computing, Ecole Polytechnique 2021-2022)","type":"book"},{"authors":null,"categories":null,"content":"   Table of Contents  Overview    Overview Optimal control, stochastic and structured bandits, model-based MDP, planning, deep reinforcement learning.\nTeaching assistant for practical sessions.\n 1. MDP Introduction to Markov Decision Processes, Bellman operators and control.   2. Bandits Introduction to stochastic and structured bandits.   3. Planning Planning in bandits: pure exploration, best arm identification. Planning in MDP: Monte Carlo Tree Search.   4. Deep Reinforcement Learning Deep RL, DQN.   ","date":1615248000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1616528642,"objectID":"e5e2928a530a60c45f32f60de350cbd1","permalink":"https://sauxpa.github.io/teaching/rl_centrale/","publishdate":"2021-03-09T00:00:00Z","relpermalink":"/teaching/rl_centrale/","section":"teaching","summary":"Introduction to reinforcement learning, control and bandits.","tags":null,"title":"Reinforcement Learning (CentraleSupelec M2 2020-2021)","type":"book"},{"authors":null,"categories":null,"content":"Introduction to Markov Decision Processes, Bellman operators and control.\nMDP Blitz Course\nPractical session\nSolution\n","date":1616198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616527845,"objectID":"1480678f1e50071c8b0a3732dc245328","permalink":"https://sauxpa.github.io/teaching/rl_centrale/01_mdp/","publishdate":"2021-03-20T00:00:00Z","relpermalink":"/teaching/rl_centrale/01_mdp/","section":"teaching","summary":"Markov Decision Processes, Bellman operators.","tags":null,"title":"1. MDP","type":"book"},{"authors":null,"categories":null,"content":"Introduction to stochastic and structured bandits.\nBandits Blitz Course\nPractical session\nForban (bandit library)\n","date":1616198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617122493,"objectID":"a1048fcda0f709d95caa829f7f6987ce","permalink":"https://sauxpa.github.io/teaching/rl_centrale/02_bandits/","publishdate":"2021-03-20T00:00:00Z","relpermalink":"/teaching/rl_centrale/02_bandits/","section":"teaching","summary":"Stochastic and structured bandits.","tags":null,"title":"2. Bandits","type":"book"},{"authors":null,"categories":null,"content":"Policy gradient, Reinforce, PPO, Unity.\nPractical session Answers\n","date":1644969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645023190,"objectID":"32deb6eefe077de29d1791b74891832f","permalink":"https://sauxpa.github.io/teaching/rl_x_2022/deep_rl/","publishdate":"2022-02-16T00:00:00Z","relpermalink":"/teaching/rl_x_2022/deep_rl/","section":"teaching","summary":"Policy gradient, Reinforce, PPO, Unity.","tags":null,"title":"Deep Reinforcement Learning","type":"book"},{"authors":null,"categories":null,"content":"Model-based MDP: value iteration when the transition probabilities and rewards are known, UCRL algorithms when they are estimated from observations.\nPractical session Answers\n","date":1644364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644418413,"objectID":"f443c1ab1566c9e7e109475fbf0d561a","permalink":"https://sauxpa.github.io/teaching/rl_x_2022/model_based/","publishdate":"2022-02-09T00:00:00Z","relpermalink":"/teaching/rl_x_2022/model_based/","section":"teaching","summary":"Model-based, Value iteration, UCRL.","tags":null,"title":"Model-based","type":"book"},{"authors":null,"categories":null,"content":"Planning in bandits: pure exploration, best arm identification. Planning in MDP: Monte Carlo Tree Search.\nPractical session - Best arm identification\nPractical session - MCTS on TicTacToe\nAnswers - Best arm identification\nAnswers - MCTS on TicTacToe\n","date":1643155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645381682,"objectID":"1e747cc483516ea6ed43e55938bfbc6a","permalink":"https://sauxpa.github.io/teaching/rl_x_2022/planning/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/teaching/rl_x_2022/planning/","section":"teaching","summary":"Planning, MCTS, best arm identification.","tags":null,"title":"Planning","type":"book"},{"authors":null,"categories":null,"content":"Planning in bandits: pure exploration, best arm identification. Planning in MDP: Monte Carlo Tree Search.\nPractical session - Best arm identification\nForban (bandit library)\nPractical session - MCTS on TicTacToe\n","date":1617062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617186107,"objectID":"8f4615a17f25d3316ada4aa99a83f806","permalink":"https://sauxpa.github.io/teaching/rl_centrale/03_planning/","publishdate":"2021-03-30T00:00:00Z","relpermalink":"/teaching/rl_centrale/03_planning/","section":"teaching","summary":"Planning, MCTS, best arm identification.","tags":null,"title":"3. Planning","type":"book"},{"authors":null,"categories":null,"content":"Deep RL, DQN.\nDQN Blitz Course\nPractical session - DQN\n","date":1617580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617662775,"objectID":"cbb976d31a6460c5b4a8e679fb8846ad","permalink":"https://sauxpa.github.io/teaching/rl_centrale/04_drl/","publishdate":"2021-04-05T00:00:00Z","relpermalink":"/teaching/rl_centrale/04_drl/","section":"teaching","summary":"Deep RL, DQN.","tags":null,"title":"4. Deep Reinforcement Learning","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609198536,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://sauxpa.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1604929626,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"6e15a4e349b75dafb8ab876a7317f771","permalink":"https://sauxpa.github.io/projects/stochastic/","publishdate":"2020-11-09T14:47:06+01:00","relpermalink":"/projects/stochastic/","section":"projects","summary":"All sorts of stochastic simulations.","tags":[],"title":"Stochastic","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1604927426,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"feecc7486f840c26eb15ba6fdfc4efbf","permalink":"https://sauxpa.github.io/projects/ito-diffusions/","publishdate":"2020-11-09T14:10:26+01:00","relpermalink":"/projects/ito-diffusions/","section":"projects","summary":"Libraries for stochastic processes simulation and visualization.","tags":[],"title":"ito-diffusions","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1591020767,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"12f2e71addb86de74cd59e74792de14f","permalink":"https://sauxpa.github.io/projects/bond_pricer/","publishdate":"2020-06-01T15:12:47+01:00","relpermalink":"/projects/bond_pricer/","section":"projects","summary":"Interactive bond pricer, yield calculation and Monte Carlo pricing for callable.","tags":[],"title":"Bond pricer","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1588428907,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"f973500daf8d6c8994dd299041694048","permalink":"https://sauxpa.github.io/projects/expander_graphs/","publishdate":"2020-05-02T15:15:07+01:00","relpermalink":"/projects/expander_graphs/","section":"projects","summary":"Implementation of several expanders and empirical evidence of spectral and connectivity properties. Contribution to the networkx library.","tags":[],"title":"Expander graphs","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1588083461,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"ece1ef66897d8ab7a0a05d4a200e80c1","permalink":"https://sauxpa.github.io/projects/random_matrices/","publishdate":"2020-04-28T15:17:41+01:00","relpermalink":"/projects/random_matrices/","section":"projects","summary":"Web app on spectral properties of large random matrices.","tags":[],"title":"Random matrices","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1587821864,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"8f7316eb36f1f0550b5a6e89b7b1540a","permalink":"https://sauxpa.github.io/projects/markov-epidemic/","publishdate":"2020-04-25T14:37:44+01:00","relpermalink":"/projects/markov-epidemic/","section":"projects","summary":"Markov stochastic models (SIS, SIR, SEIR...) to describe the evolution of epidemics on a network of connected individuals.","tags":[],"title":"Markov Epidemic","type":"projects"},{"authors":["Patrick Saux"],"categories":[""],"content":"A few years ago, I had the chance to work at ENS Cachan (now ENS Paris-Saclay) on statistical inference of networks based on how information propagates on them. Back then, we used to think in terms of networks of individuals subject to diseases that spread among neighbors, but more realistic application domains were thought to be computer malwares or viral marketing online. Obviously times have changed, and with several weeks of lockdown ahead, I thought about revisiting some of this work in the light of the recent events.\nThis article aims to describe a simple model to simulate random disease outbreak and provide empirical evidence of the role of the network topology. In layman\u0026rsquo;s terms, the sparser the network, such as one describing a population under lockdown, the slower the propagation and the flatter the epidemic peak.\nThis post is intended to be fairly non-technical. All experiments shown are based on numerical models and do not claim to accurately represent real-life epidemics. All the code (a small Python library and a few notebooks) and more detailed mathematical explanations can be found HERE.\nWhy stochastic models? The use of randomness to simulate complex systems is ubiquitous in mathematics, engineering and sciences in general. The general principle is to build an engine to generate plausible scenarios for the evolution of the system and sample multiple independent realizations to study the average or extreme behaviors.\nBefore we move on to such models, let us briefly recall some standard deterministic models in epidemiology. These are called compartmental models, because they model the evolution of a patient as going through successive stages, or compartments. Three popular variants of this idea are :\n  Susceptible-Infected-Recovered (SIR) : all patients are initially susceptible, then can be infected, and then are removed from the system (either they are fully immune or they died),\n  Susceptible-Infected-Susceptible (SIS) : same but patients can be infected multiple times,\n  Susceptible-Exposed-Infectious-Recovered (SEIR) : similar to SIR, with an extra compartment to model incubation time, during which patient are not yet infectious.\n  Under mean-field assumptions, i.e every individual in a large population shares the same likelihood of being infected by the rest, one can derive a deterministic system of differential equations describing the evolution of the fraction of infected individuals (see for example Kephart \u0026amp; White).\nWhile such models are easy to understand and scale very well, they lack any description of the fine structure of the underlying social network. For example, what if the network contains highly social individuals that may act as hubs for the propagation?\nMarkov models A large class of popular stochastic models follow the Markov property : the future evolution depends only on the present state, not the past history. While debatable, it allows for very flexible still numerically tractable models.\nConsider a network G, that is a list of individuals (for instance 1, \u0026hellip;, N) and a list of pairs (i, j) if individuals i and j are neighbors. We will stick to this simple framework, but generalization to weighted or directed networks is straightforward.\nSIS, SIR and SEIR can be naturally translated to the language of Markov processes by specifying the probability of transition between compartments. As is customary with continuous-time processes, we will actually define the transition rates rather than the probability (the two are related by the fact that transition events follow exponential distributions with parameters equal to the transition rates).\nFor any individual, we assume a transition susceptible -\u0026gt; infected (or susceptible -\u0026gt; exposed in SEIR) at rate proportional to the number of infected neighbors. This is quite natural: the more one is surrounded by infectious people, the riskier (note that here again there is room for more complicated designs by using a nonlinear aggregation function over the neighbors). The other transitions, (I-\u0026gt;S in SIS, I-\u0026gt;R in SIR, E-\u0026gt;I and I-\u0026gt;R in SEIR) are assumed to occur at constant rates (think of it as sick people being put in isolation).\nExperiments SIR First let us simulate the effect of a severe lockdown in SIR. For that, we compare the evolution of the number of cases for the same epidemic (same transition rates parameters) on two different regular networks :\n sparse: every node is connected to 10 other nodes, dense: every node is connected to 100 other nodes.  In the sparse scenario, a typical outbreak has a long plateau and a slow decrease, but a much smaller peak. In the dense case, almost all the population gets infected at a very early stage, creating a sharp peak, followed by a brutal, but slower decrease. The blue curve below is a typical lockdown strategic goal (flat and slow) while the red curve is more inline with a herd immunity viewpoint.\n  To be a bit more quantitative about the shape of the curve, one can try to regress a parametric form on it. In all experiments, sparse SIR leads to an approximately normal form while dense SIR is better fitted by a skewed shape such as lognormal. In other words, network sparsification is not just about flattening the curve, but also controlling the slope.\nHub effect Another empirical effect is the Hub effect, which is that highly connected nodes are critical for propagation. This typically happens in social networks (a few very popular nodes attract most of the attention) and can be described as preferential attachment networks: starting from a small population of nodes, a larger network is grown by adding follower nodes that connect to the existing ones with probability proportional to the number of already existing neighbors.\nIn the case of SIS over a preferential attachment network, we compare two outbreak scenarios:\n a single patient zero, the one with the most neighbors, 5 patient zeros, drawn at random (and therefore likely to be follower nodes).  Unless a hub is targeted, the epidemic usually dies fast without reaching highly-connected zones, even with more initial patients.\n  Comparison with deterministic models As argued above, deterministic models à la Kephart \u0026amp; White can be seen as scaling limits of Markov models on regular networks, i.e when the local structure of the network is the same everywhere one looks.\nThis is indeed empirically validated, see for example in the case of SIR and SIS below.\n  SIR    SIS  Comparison with real data (as of April 2020) This is still a work-in-progress, made practically difficult by the number and quality of available data. One interesting direction would be to fit one of these models (for example SEIR) to the curve of tested cases of COVID-19 (which is typically noisy and subject to bias, including periodic bias, for instance during the week-ends when medical staff are not tested).\nTo be clear, calibrating the model here means tuning the transition rates for S-\u0026gt;E, E-\u0026gt;I and I-\u0026gt;R such that the average curve over multiple epidemic scenarios resembles the most the collected data (for the example in the least squares sense).\nFrom there, one could investigate different types of representative networks to determine the ones that reproduce the best the observed trends, and use this as a starting point for further predictions (epidemic evolution, impact of lockdown exit\u0026hellip;).\n  Going further A very attractive aspect of stochastic simulation is the ability to perform numerical experiments. However, the topic of random processes over networks has been studied a lot on the theoretical side as well. A few selected references include :\n  Virus Spreads in Networks by Van Mieghem et al., which formalizes the definition of epidemic as a Markov process on the configuration space,\n  The Effect of Network Topology on the Spread of Epidemics by Massoulié et al., which exhibits a phase transition between short-lived and long-lived epidemics in terms of the transition rates and the adjacency spectral radius of the network,\n  Got the Flu (or Mumps)? Check the Eigenvalue! in the same spirit, which relates spectral properties of the network to critical epidemic regimes in different models.\n  Also check out this repo for more implementation details, including a Bokeh app to dynamically play with different network and epidemic parameters.\n  Enjoy!\nLicense Copyright 2020-present Patrick Saux.\n","date":1587686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618225264,"objectID":"e2dfa803bac6d8a5d57eb3493bc5047c","permalink":"https://sauxpa.github.io/post/markov_epidemic/","publishdate":"2020-04-24T00:00:00Z","relpermalink":"/post/markov_epidemic/","section":"post","summary":"A humble lockdown project to model the interplay between the structure of a network and the spread of epidemics over it.","tags":[""],"title":"Markov Epidemic, a stochastic model for disease outbreak","type":"post"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1579356461,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"a063d64ba38a968c8b560c050d4f7f22","permalink":"https://sauxpa.github.io/projects/neural_exploration/","publishdate":"2020-01-18T15:07:41+01:00","relpermalink":"/projects/neural_exploration/","section":"projects","summary":"Analysis and implementation of neural approximator for contextual bandits and episodic MDP.","tags":[],"title":"Neural exploration","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1577887203,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"ed9809f516f3af6869363134b70a4217","permalink":"https://sauxpa.github.io/projects/graph_embedding/","publishdate":"2020-01-01T15:00:03+01:00","relpermalink":"/projects/graph_embedding/","section":"projects","summary":"Theoretical and practical continuity of various graph embeddings (eigenmap, deep walk, graph kernels, random walk factorisation...)","tags":[],"title":"Continuity of Graph Embeddings","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1577282295,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615370361,"objectID":"7402895a941774a48bd56f9b52e5c8dd","permalink":"https://sauxpa.github.io/projects/optimal_transport_correlation/","publishdate":"2019-12-25T14:58:15+01:00","relpermalink":"/projects/optimal_transport_correlation/","section":"projects","summary":"Geometric study of correlation matrix via Frechet mean.","tags":[],"title":"Optimal Transport Correlation","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1576417816,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"233a42a9516aaf734380d600628218cc","permalink":"https://sauxpa.github.io/projects/connectivity-loss/","publishdate":"2019-12-15T14:50:16+01:00","relpermalink":"/projects/connectivity-loss/","section":"projects","summary":"Train robust autoencoder with topological loss.","tags":[],"title":"Connectivity Loss","type":"projects"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":1563113997,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615369729,"objectID":"f66b41ad514ffefa0c2cb0802684d851","permalink":"https://sauxpa.github.io/projects/fractal/","publishdate":"2019-07-14T15:19:57+01:00","relpermalink":"/projects/fractal/","section":"projects","summary":"Fractal generation in Python using Just-In-Time (JIT) compilation and Numba.","tags":[],"title":"Fractal","type":"projects"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612908990,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://sauxpa.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":["Dorian Baudry","Patrick Saux","Odalric-Ambrym Maillard"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -- ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637243973,"objectID":"b8c74902f551356a2be2979ce3cc8929","permalink":"https://sauxpa.github.io/research/dirichlet_sampling/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/dirichlet_sampling/","section":"research","summary":"The stochastic multi-arm bandit problem has been extensively studied under standard assumptions on the arm's distribution (e.g bounded with known support, exponential family, etc). These assumptions are suitable for many real-world problems but sometimes they require knowledge (on tails for instance) that may not be precisely accessible to the practitioner, raising the question of the robustness of bandit algorithms to model misspecification. In this paper we study a generic Dirichlet Sampling (DS) algorithm, based on pairwise comparisons of empirical indices computed with re-sampling of the arms' observations and a data-dependent exploration bonus. We show that different variants of this strategy achieve provably optimal regret guarantees when the distributions are bounded and logarithmic regret for semi-bounded distributions with a mild quantile condition. We also show that a simple tuning achieve robustness with respect to a large class of unbounded distributions, at the cost of slightly worse than logarithmic asymptotic regret. We finally provide numerical experiments showing the merits of DS in a decision-making problem on synthetic agriculture data.","tags":[],"title":"From Optimality to Robustness: Dirichlet Sampling Strategies in Stochastic Bandits","type":"research"},{"authors":[],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651727901,"objectID":"f5d0608e10f5303e91898860bbf7c138","permalink":"https://sauxpa.github.io/talks/sophia_hillerod/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/sophia_hillerod/","section":"talks","summary":"Weight trajectory after bariatric surgery.","tags":[],"title":"General Assembly SOPHIA","type":"talks"},{"authors":["Patrick Saux"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645516663,"objectID":"572e0381def502896b04aef894b1993d","permalink":"https://sauxpa.github.io/projects/rlberry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/rlberry/","section":"projects","summary":"A Reinforcement Learning Library for Research and Education.","tags":[],"title":"rlberry","type":"projects"},{"authors":[],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651727901,"objectID":"4f6b73a98e720b8f8860bc6a562b33f8","permalink":"https://sauxpa.github.io/talks/scool_seminar_ds/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/scool_seminar_ds/","section":"talks","summary":"From Optimality to Robustness: Dirichlet Sampling Strategies in Stochastic Bandits.","tags":[],"title":"Scool Seminar","type":"talks"}]